# -*- coding: utf-8 -*-
"""preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yVjhqTDBi4gf8pw-95cfRpBdTA-tJrE0
"""

import pandas as pd

books_df = pd.read_csv('Book_Details.csv', index_col=0)

books_df['genres'] = books_df['genres'].apply(lambda x: eval(x))
books_df['genres'] = books_df['genres'].apply(lambda x: ' '.join(x))
books_df['book_details'] = books_df['book_details'].fillna('')

books_df['combined_features'] = books_df['book_title'] + ' ' + books_df['book_details'] + ' ' + books_df['author'] + ' ' + books_df['genres']


import re
import nltk

nltk.download('stopwords')
nltk.download('wordnet')
lst_stopwords = nltk.corpus.stopwords.words("english")

def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True):#, lst_stopwords=None):
    ## clean (convert to lowercase and remove punctuations and characters and then strip)
    text = re.sub(r'[^\w\s]', '', str(text).lower().strip())

    ## Tokenize (convert from string to list)
    lst_text = text.split()
    ## remove Stopwords
    if lst_stopwords is not None:
        lst_text = [word for word in lst_text if word not in
                    lst_stopwords]

    ## Stemming (remove -ing, -ly, ...)
    if flg_stemm == True:
        ps = nltk.stem.porter.PorterStemmer()
        lst_text = [ps.stem(word) for word in lst_text]

    ## Lemmatisation (convert the word into root word)
    if flg_lemm == True:
        lem = nltk.stem.wordnet.WordNetLemmatizer()
        lst_text = [lem.lemmatize(word) for word in lst_text]

    ## back to string from list
    text = " ".join(lst_text)
    return text

books_df["preprocessed_text"] = books_df["book_details"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True))
books_df["genres"] = books_df["genres"].apply(lambda x: utils_preprocess_text(x))
books_df["author"] = books_df["author"].apply(lambda x: utils_preprocess_text(x))
books_df["combined_features"] = books_df["combined_features"].apply(lambda x: utils_preprocess_text(x))

books_df.to_csv('processed_books_df.csv', index=False)
training_df = books_df.head(5000)
training_df.to_csv('training.csv', index=False)